<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.0" />
<title>quagmire.surfmesh.surfmesh API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>quagmire.surfmesh.surfmesh</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright 2016-2020 Louis Moresi, Ben Mather, Romain Beucher
# 
# This file is part of Quagmire.
# 
# Quagmire is free software: you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation, either version 3 of the License, or any later version.
# 
# Quagmire is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public License
# along with Quagmire.  If not, see &lt;http://www.gnu.org/licenses/&gt;.

import numpy as np
from mpi4py import MPI
import sys,petsc4py
petsc4py.init(sys.argv)
from petsc4py import PETSc
# comm = MPI.COMM_WORLD
from time import perf_counter

try: range = xrange
except: pass


from quagmire import function as fn
from ..mesh import MeshVariable as _MeshVariable
from ..topomesh import TopoMesh as _TopoMesh

class SurfMesh(_TopoMesh):

    def __init__(self, *args, **kwargs):
        super(SurfMesh,self).__init__(*args, **kwargs)

        # self.kappa = 1.0 # dummy value

        ## Variables that are needed by default methods

        # self.rainfall_pattern_Variable = self.add_variable(name=&#34;precipitation&#34;)
        # self.sediment_distribution_Variable = self.add_variable(name=&#34;sediment&#34;)

        # new context manager ...
        self.deform_topography = self._height_update_context_manager_generator()
        self.upstream_area     = self.add_variable(name=&#34;A(x,y)&#34;, locked=True)

    ## Not sure if it is best to inherit this manager and extend it or to
    ## redefine / over-ride it. Only the exit method has changed.

    def _height_update_context_manager_generator(self):
        &#34;&#34;&#34;Builds a context manager on the current object to control when matrices are to be updated&#34;&#34;&#34;

        surfmesh = self
        topographyVariable = self.topography

        class Surfmesh_Height_Update_Manager(object):
            &#34;&#34;&#34;Manage when changes to the height information trigger a rebuild
            of the topomesh matrices and other internal data.
            &#34;&#34;&#34;

            def __init__(inner_self):
                inner_self.surfmesh = surfmesh
                inner_self._topovar  = topographyVariable
                return

            def __enter__(inner_self):
                # unlock
                inner_self._topovar.unlock()
                return

            def __exit__(inner_self, *args):
                inner_self.surfmesh._update_height()
                inner_self.surfmesh._update_height_for_surface_flows()
                inner_self._topovar.lock()
                return

        return Surfmesh_Height_Update_Manager


    def _update_height_for_surface_flows(self):

        from time import clock
        #self.rainfall_pattern = rainfall_pattern.copy()
        #self.sediment_distribution = sediment_distribution.copy()

        t = perf_counter()

        self.upstream_area.unlock()
        self.upstream_area.data = self.cumulative_flow(self.area)
        self.upstream_area.lock()

        self.timings[&#39;Upstream area&#39;] = [perf_counter()-t, self.log.getCPUTime(), self.log.getFlops()]

        if self.verbose:
            print((&#34;{} - Build upstream areas {}s&#34;.format(self.dm.comm.rank, perf_counter()-t)))

        # Find low points
        self.low_points = self.identify_low_points()

        # Find high points
        self.outflow_points = self.identify_outflow_points()



    def low_points_local_flood_fill(self, its=99999, scale=1.0, smoothing_steps=2):
        &#34;&#34;&#34;
        Fill low points with a local flooding algorithm.
          - its is the number of uphill propagation steps
          - scale
        &#34;&#34;&#34;

        t = perf_counter()
        if self.rank==0 and self.verbose:
            print(&#34;Low point local flood fill&#34;)

        my_low_points = self.identify_low_points()

        self.topography.unlock()
        h = self.topography.data

        fill_height =  (h[self.neighbour_cloud[my_low_points,1:7]].mean(axis=1)-h[my_low_points])

        new_h = self.uphill_propagation(my_low_points,  fill_height, scale=scale,  its=its, fill=0.0)
        new_h = self.sync(new_h)

        smoothed_new_height = self.rbf_smoother(new_h, iterations=smoothing_steps)
        self.topography.data = np.maximum(0.0, smoothed_new_height) + h
        self.topography.sync()
        self.topography.lock()
        self._update_height()

        if self.rank==0 and self.verbose:
            print(&#34;Low point local flood fill &#34;,  perf_counter()-t, &#34; seconds&#34;)

        self._update_height_for_surface_flows()

        return

    def low_points_local_patch_fill(self, its=1, smoothing_steps=1):

        from petsc4py import PETSc
        t = perf_counter()
        if self.rank==0 and self.verbose:
            print(&#34;Low point local patch fill&#34;)

        for iteration in range(0,its):
            low_points = self.identify_low_points()

            self.topography.unlock()

            h = self.topography.data
            delta_height = np.zeros_like(h)

            ## Note, the smoother has a communication barrier so needs to be called even if it has no work to do on this process

            if len(low_points) != 0:
                delta_height[low_points] =  (h[self.neighbour_cloud[low_points,1:5]].mean(axis=1) -
                                                         h[low_points])
            ## Note, the smoother has a communication barrier so needs to be called even
            ## if len(low_points==0) and there is no work to do on this process
            smoothed_height = self.rbf_smoother(h+delta_height, iterations=smoothing_steps)

            self.topography.data = np.maximum(smoothed_height, h)
            self.topography.sync()
            self.topography.lock()
            self._update_height()

        if self.rank==0 and self.verbose:
            print(&#34;Low point local patch fill &#34;,  perf_counter()-t, &#34; seconds&#34;)

        ## and now we need to rebuild the surface process information
        self._update_height_for_surface_flows()

        return


    def low_points_swamp_fill(self, its=1000, saddles=True, ref_height=0.0):

        import petsc4py
        from petsc4py import PETSc
        from mpi4py import MPI

        comm = MPI.COMM_WORLD
        size = comm.Get_size()
        rank = comm.Get_rank()

        t0 = perf_counter()

        my_low_points = self.identify_low_points()
        my_glow_points = self.lgmap_row.apply(my_low_points.astype(PETSc.IntType))


        t = perf_counter()
        ctmt = self.uphill_propagation(my_low_points,  my_glow_points, its=its, fill=-999999).astype(np.int)

        if self.rank==0 and self.verbose:
            print(&#34;Build low point catchments - &#34;, perf_counter() - t, &#34; seconds&#34;)

        if saddles:  # Find saddle points on the catchment edge
            cedges = np.where(ctmt[self.down_neighbour[2]] != ctmt )[0] ## local numbering
        else:        # Fine all edge points
            ctmt2 = ctmt[self.neighbour_cloud] - ctmt.reshape(-1,1)
            ctmt3 = ctmt2 * self.near_neighbour_mask
            cedges = np.where(ctmt3.any(axis=1))[0]

        outer_edges = np.where(~self.bmask)[0]
        edges = np.unique(np.hstack((cedges,outer_edges)))

        height = self.topography.data.copy()

        ## In parallel this is all the low points where this process may have a spill-point
        my_catchments = np.unique(ctmt)

        spills = np.empty((edges.shape[0]),
                         dtype=np.dtype([(&#39;c&#39;, int), (&#39;h&#39;, float), (&#39;x&#39;, float), (&#39;y&#39;, float)]))

        ii = 0
        for l, this_low in enumerate(my_catchments):
            this_low_spills = edges[np.where(ctmt[edges] == this_low)]  ## local numbering

            for spill in this_low_spills:
                spills[&#39;c&#39;][ii] = this_low
                spills[&#39;h&#39;][ii] = height[spill]
                spills[&#39;x&#39;][ii] = self.coords[spill,0]
                spills[&#39;y&#39;][ii] = self.coords[spill,1]
                ii += 1

        t = perf_counter()

        spills.sort(axis=0)  # Sorts by catchment then height ...
        s, indices = np.unique(spills[&#39;c&#39;], return_index=True)
        spill_points = spills[indices]

        if self.rank == 0 and self.verbose:
            print(self.rank, &#34; Sort spills - &#34;, perf_counter() - t)

        # Gather lists to process 0, stack and remove duplicates

        t = perf_counter()
        list_of_spills = comm.gather(spill_points,   root=0)

        if self.rank == 0 and self.verbose:
            print(self.rank, &#34; Gather spill data - &#34;, perf_counter() - t)

        if self.rank == 0:
            t = perf_counter()

            all_spills = np.hstack(list_of_spills)
            all_spills.sort(axis=0) # Sorts by catchment then height ...
            s, indices = np.unique(all_spills[&#39;c&#39;], return_index=True)
            all_spill_points = all_spills[indices]

            if self.verbose:
                print(rank, &#34; Sort all spills - &#34;, perf_counter() - t)

        else:
            all_spill_points = None
            pass

        # Broadcast lists to everyone

        global_spill_points = comm.bcast(all_spill_points, root=0)

        height2 = np.zeros_like(height) + ref_height

        for i, spill in enumerate(global_spill_points):
            this_catchment = int(spill[&#39;c&#39;])

            ## -ve values indicate that the point is connected
            ## to the outflow of the mesh and needs no modification
            if this_catchment &lt; 0:
                continue

            catchment_nodes = np.where(ctmt == this_catchment)
            separation_x = (self.coords[catchment_nodes,0] - spill[&#39;x&#39;])
            separation_y = (self.coords[catchment_nodes,1] - spill[&#39;y&#39;])
            distance = np.hypot(separation_x, separation_y)

            height2[catchment_nodes] = spill[&#39;h&#39;] + 0.000001 * distance  # A &#39;small&#39; gradient (should be a user-parameter)

        height2 = self.sync(height2)

        new_height = np.maximum(height, height2)
        new_height = self.sync(new_height)


        # We only need to update the height not all
        # surface process information that is associated with it.
        self.topography.unlock()
        self.topography.data = new_height
        self._update_height()
        self.topography.lock()


        if self.rank==0 and self.verbose:
            print(&#34;Low point swamp fill &#34;,  perf_counter()-t0, &#34; seconds&#34;)

        ## but now we need to rebuild the surface process information
        self._update_height_for_surface_flows()
        return


    def backfill_points(self, fill_points, heights, its):
        &#34;&#34;&#34;
        Handles *selected* low points by backfilling height array.
        This can be used to block a stream path, for example, or to locate lakes
        &#34;&#34;&#34;

        if len(fill_points) == 0:
            return self.heightVariable.data

        new_height = self.lvec.duplicate()
        new_height.setArray(heights)
        height = np.maximum(self.height, new_height.array)

        # Now march the new height to all the uphill nodes of these nodes
        # height = np.maximum(self.height, delta_height.array)

        self.dm.localToGlobal(new_height, self.gvec)
        global_dH = self.gvec.copy()

        for p in range(0, its):
            self.adjacency[1].multTranspose(global_dH, self.gvec)
            global_dH.setArray(self.gvec)
            global_dH.scale(1.001)  # Maybe !
            self.dm.globalToLocal(global_dH, new_height)

            height = np.maximum(height, new_height.array)

        return height

    def uphill_propagation(self, points, values, scale=1.0, its=1000, fill=-1):

        t0 = perf_counter()

        local_ID = self.lvec.copy()
        global_ID = self.gvec.copy()

        local_ID.set(fill+1)
        global_ID.set(fill+1)

        identifier = np.empty_like(self.topography.data)
        identifier.fill(fill+1)

        if len(points):
            identifier[points] = values + 1

        local_ID.setArray(identifier)
        self.dm.localToGlobal(local_ID, global_ID)

        delta = global_ID.copy()
        delta.abs()
        rtolerance = delta.max()[1] * 1.0e-10

        for p in range(0, its):

            # self.adjacency[1].multTranspose(global_ID, self.gvec)
            gvec = self.uphill[1] * global_ID
            delta = global_ID - gvec
            delta.abs()
            max_delta = delta.max()[1]

            if max_delta &lt; rtolerance:
                break

            self.gvec.scale(scale)

            if self.dm.comm.Get_size() == 1:
                local_ID.array[:] = gvec.array[:]
            else:
                self.dm.globalToLocal(gvec, local_ID)

            global_ID.array[:] = gvec.array[:]

            identifier = np.maximum(identifier, local_ID.array)
            identifier = self.sync(identifier)

        # Note, the -1 is used to identify out of bounds values

        if self.rank == 0 and self.verbose:
            print(p, &#34; iterations, time = &#34;, perf_counter() - t0)

        return identifier - 1



    def identify_low_points(self, include_shadows=False):
        &#34;&#34;&#34;
        Identify if the mesh has (internal) local minima and return an array of node indices
        &#34;&#34;&#34;

        # from petsc4py import PETSc

        nodes = np.arange(0, self.npoints, dtype=np.int)
        gnodes = self.lgmap_row.apply(nodes.astype(PETSc.IntType))

        low_nodes = self.down_neighbour[1]
        mask = np.logical_and(nodes == low_nodes, self.bmask == True)

        if not include_shadows:
            mask = np.logical_and(mask, gnodes &gt;= 0)

        return nodes[mask]

    def identify_global_low_points(self, global_array=False):
        &#34;&#34;&#34;
        Identify if the mesh as a whole has (internal) local minima and return an array of local lows in global
        index format.

        If global_array is True, then lows for the whole mesh are returned
        &#34;&#34;&#34;

        import petsc4py
        from petsc4py import PETSc
        from mpi4py import MPI

        comm = MPI.COMM_WORLD
        size = comm.Get_size()
        rank = comm.Get_rank()

        # from petsc4py import PETSc

        nodes = np.arange(0, self.npoints, dtype=np.int)
        gnodes = self.lgmap_row.apply(nodes.astype(PETSc.IntType))

        low_nodes = self.down_neighbour[1]
        mask = np.logical_and(nodes == low_nodes, self.bmask == True)
        mask = np.logical_and(mask, gnodes &gt;= 0)

        number_of_lows = np.count_nonzero(mask)
        low_gnodes = self.lgmap_row.apply(low_nodes.astype(PETSc.IntType))

        # gather/scatter numbers

        list_of_nlows  = comm.gather(number_of_lows,   root=0)
        if self.rank == 0:
            all_low_counts = np.hstack(list_of_nlows)
            no_global_lows0 = all_low_counts.sum()

        else:
            no_global_lows0 = None

        no_global_lows = comm.bcast(no_global_lows0, root=0)


        if global_array:

            list_of_lglows = comm.gather(low_gnodes,   root=0)

            if self.rank == 0:
                all_glows = np.hstack(list_of_lglows)
                global_lows0 = np.unique(all_glows)

            else:
                global_lows0 = None

            low_gnodes = comm.bcast(global_lows0, root=0)

        return no_global_lows, low_gnodes


    def identify_outflow_points(self):
        &#34;&#34;&#34;
        Identify the (boundary) outflow points and return an array of (local) node indices
        &#34;&#34;&#34;

        # nodes = np.arange(0, self.npoints, dtype=np.int)
        # low_nodes = self.down_neighbour[1]
        # mask = np.logical_and(nodes == low_nodes, self.bmask == False)
        #

        i = self.downhill_neighbours

        o = (np.logical_and(self.down_neighbour[i] == np.indices(self.down_neighbour[i].shape), self.bmask == False)).ravel()
        outflow_nodes = o.nonzero()[0]

        return outflow_nodes


    def identify_flat_spots(self):

        slope = self.slope.evaluate(self.slope._mesh)
        smooth_grad1 = self.local_area_smoothing(slope, its=1, centre_weight=0.5)

        # flat_spot_field = np.where(smooth_grad1 &lt; smooth_grad1.max()/100, 0.0, 1.0)

        flat_spots = np.where(smooth_grad1 &lt; smooth_grad1.max()/1000.0, True, False)

        return flat_spots


    def stream_power_erosion_deposition_rate_old(self, efficiency=0.01, smooth_power=3, \
                                             smooth_low_points=2, smooth_erosion_rate=2, \
                                             smooth_deposition_rate=2, smooth_operator=None,
                                             centre_weight_u=0.5, centre_weight=0.5):

        &#34;&#34;&#34;
        Function of the SurfaceProcessMesh which computes stream-power erosion and deposition rates
        from a given rainfall pattern (self.rainfall_pattern).

        In this model we assume a the carrying capacity of the stream is related to the stream power and so is the
        erosion rate. The two are related to one another in this particular case by a single contant (everywhere on the mesh)
        This does not allow for spatially variable erodability and it does not allow for differences in the dependence
        of erosion / deposition on the stream power.

        Deposition occurs such that the upstream-integrated eroded sediment does not exceed the carrying capacity at a given
        point. To conserve mass, we have to treat internal drainage points carefully and, optionally, smooth the deposition
        upstream of the low point. We also have to be careful when stream-power and carrying capacity increase going downstream.
        This produces a negative deposition rate when the flow is at capacity. We suppress this behaviour and balance mass across
        all other deposition sites but this does mean the capacity is not perfectly satisfied everywhere.

        parameters:
         efficiency=0.01          : erosion rate for a given stream power compared to carrying capacity
         smooth_power=3           : upstream / downstream smoothing of the stream power (number of cycles of smoothing)
         smooth_low_points=3      : upstream smoothing of the deposition at low points (number of cycles of smoothing)
         smooth_erosion_rate=0    : upstream / downstream smoothing of the computed erosion rate (number of cycles of smoothing)
         smooth_deposition_rate=0 : upstream / downstream smoothing of the computed erosion rate (number of cycles of smoothing)

        &#34;&#34;&#34;


        if smooth_operator == None:
            smooth_operator = self.streamwise_smoothing

        # Calculate stream power

        ## Model 1 - Local equilibrium

        rainflux = self.rainfall_pattern
        rainfall = self.area * rainflux
        cumulative_rain = self.cumulative_flow(rainfall)

        cumulative_flow_rate = cumulative_rain / self.area

        stream_power = self.uphill_smoothing(cumulative_flow_rate * self.slopeVariable.data, smooth_power, centre_weight=centre_weight_u)

        #  predicted erosion rate from stream power * efficiency
        #  maximum sediment that can be transported is limited by the local carrying capacity (assume also prop to stream power)
        #  whatever cannot be passed on has to be deposited

        erosion_rate = self.streamwise_smoothing(efficiency * stream_power, smooth_erosion_rate, centre_weight=centre_weight)
        full_capacity_sediment_flux = stream_power
        full_capacity_sediment_load = stream_power * self.area
        cumulative_eroded_material = self.cumulative_flow(self.area * erosion_rate)

        # But this can exceed the carrying capacity

        transport_limited_eroded_material = np.minimum(cumulative_eroded_material, full_capacity_sediment_load)
        transport_limited_erosion_rate = transport_limited_eroded_material / self.area

        # And this therefore implies a deposition rate which reduces the total sediment in the system to capacity
        # Calculate this by substracting the deposited amounts from the excess integrated flow. We could then iterate
        # to compute the new erosion rates etc, but here we just spread the sediments around to places where
        # the deposition is positive

        excess = self.gvec.duplicate()
        deposition = self.lvec.duplicate()
        self.lvec.setArray(cumulative_eroded_material - transport_limited_eroded_material)
        self.dm.localToGlobal(self.lvec, excess)
        self.downhillMat.mult(excess, self.gvec)
        self.dm.globalToLocal(excess - self.gvec, deposition)
        depo_sum = deposition.sum()


        # Now rebalance the fact that we have clipped off the negative deposition which will need
        # to be clawed back downstream (ideally, but for now we can just make a global correction)

        deposition = np.clip(deposition.array, 0.0, 1.0e99)
        deposition *= depo_sum / (depo_sum + 1e-12)


        # The (interior) low points are a bit of a problem - we stomped on the stream power there
        # but this produces a very lumpy deposition at the low point itself and this could (does)
        # make the numerical representation pretty unstable. Instead what we can do is to take that
        # deposition at the low points let it spill into the local area


        ## These will instead be handled by a specific routine &#34;handle_low_points&#34; which is
        ## done once the height has been updated

        if len(self.low_points):
            deposition[self.low_points] = 0.0

        # The flat regions in the domain are also problematic since the deposition there is

        flat_spots = self.identify_flat_spots()

        if len(flat_spots):
            smoothed_deposition = deposition.copy()
            smoothed_deposition[np.invert(flat_spots)] = 0.0
            smoothed_deposition = self.local_area_smoothing(smoothed_deposition, its=2, centre_weight=0.5)
            deposition[flat_spots] = smoothed_deposition[flat_spots]

        deposition_rate = smooth_operator(deposition, smooth_deposition_rate, centre_weight=centre_weight) / self.area

        return erosion_rate, deposition_rate, stream_power



    # def landscape_diffusion_critical_slope(self, kappa, critical_slope, fluxBC):
    #     &#39;&#39;&#39;
    #     Non-linear diffusion to keep slopes at a critical value. Assumes a background
    #     diffusion rate (can be a vector of length mesh.tri.npoints) and a critical slope value.
    #
    #     This term is suitable for the sloughing of sediment from hillslopes.
    #
    #     To Do: The critical slope should be a function of the material (sediment, basement etc)
    #     but currently it is not.
    #
    #     To Do: The fluxBC flag is global ... it should apply to the outward normal
    #     at selected nodes but currently it is set to kill both fluxes at all boundary nodes.
    #     &#39;&#39;&#39;
    #
    #     inverse_bmask = np.invert(self.bmask)
    #
    #     kappa_eff = kappa / (1.01 - (np.clip(self.slopeVariable.data,0.0,critical_slope) / critical_slope)**2)
    #     self.kappa = kappa_eff
    #
    #     # get minimum timestep across the global mesh
    #     local_diffusion_timestep = np.array((self.area / kappa_eff).min())
    #     global_diffusion_timestep = np.array(0.0)
    #     self.comm.Allreduce([local_diffusion_timestep, MPI.DOUBLE], \
    #                         [global_diffusion_timestep, MPI.DOUBLE], op=MPI.MIN)
    #
    #
    #     fluxVariable = self.heightVariable.gradient(nit=3, tol=1e-3)
    #     fluxVariable.data *= kappa_eff.reshape(-1,1)
    #     if fluxBC:
    #         fluxVariable.data[inverse_bmask] = 0.0 # outward normal flux, actually
    #
    #     diffDz = self.derivative_div(*fluxVariable.data.T, nit=3, tol=1e-3)
    #     diffDz = self.sync(diffDz)
    #
    #     if not fluxBC:
    #         diffDz[inverse_bmask] = 0.0
    #
    #     return diffDz, global_diffusion_timestep
    #


    def landscape_diffusion_critical_slope(self, kappa, critical_slope, fluxBC):
        &#39;&#39;&#39;
        Non-linear diffusion to keep slopes at a critical value. Assumes a background
        diffusion rate (can be a vector of length mesh.tri.npoints) and a critical slope value.
        This term is suitable for the sloughing of sediment from hillslopes.
        To Do: The critical slope should be a function of the material (sediment, basement etc)
        but currently it is not.
        To Do: The fluxBC flag is global ... it should apply to the outward normal
        at selected nodes but currently it is set to kill both fluxes at all boundary nodes.
        &#39;&#39;&#39;

        inverse_bmask = np.invert(self.bmask)

        kappa_eff = kappa / (1.01 - (np.clip(self.slopeVariable.data,0.0,critical_slope) / critical_slope)**2)
        self.kappa = kappa_eff
        # diff_timestep   =  self.area.min() / kappa_eff.max()

        # get minimum timestep across the global mesh
        local_diffusion_timestep = np.array((self.area / kappa_eff).min())
        global_diffusion_timestep = np.array(1e24)
        self.comm.Allreduce([local_diffusion_timestep, MPI.DOUBLE], \
                            [global_diffusion_timestep, MPI.DOUBLE], op=MPI.MIN)


        gradZx, gradZy = self.derivative_grad(self.topography.data)
        gradZx = self.sync(gradZx)
        gradZy = self.sync(gradZy)
        flux_x = kappa_eff * gradZx
        flux_y = kappa_eff * gradZy

        if fluxBC:
            flux_x[inverse_bmask] = 0.0
            flux_y[inverse_bmask] = 0.0  # outward normal flux, actually

        diffDz = self.derivative_div(flux_x, flux_y)
        diffDz = self.sync(diffDz)

        if not fluxBC:
            diffDz[inverse_bmask] = 0.0

        return diffDz, global_diffusion_timestep



    def landscape_evolution_timestep(self, diffusion_rate, erosion_rate, deposition_rate, uplift_rate):
        &#34;&#34;&#34;
        Calculate the change in topography for one timestep
        &#34;&#34;&#34;

        time = 0.0
        typical_l = np.sqrt(self.area)
        critical_slope = 50.0

        slope = np.maximum(self.slopeVariable.data, critical_slope)

        erosion_deposition_rate = deposition_rate - erosion_rate

        erosion_timestep    = (self.slopeVariable.data*typical_l/(erosion_rate + 1e-12)).min()
        deposition_timestep = (self.slopeVariable.data*typical_l/(deposition_rate + 1e-12)).min()
        diffusion_timestep  = self.area.min()/np.max(self.kappa)

        local_timestep = np.array(min(erosion_timestep, deposition_timestep, diffusion_timestep))
        timestep = np.array(0.0)
        comm.Allreduce([local_timestep, MPI.DOUBLE], [timestep, MPI.DOUBLE], op=MPI.MIN)

        delta_h = timestep * (erosion_deposition_rate - diffusion_rate + uplift_rate)

        # Note this is based on local information, and must be synced
        return delta_h, timestep




    def stream_power_erosion_deposition_rate_local(self, stream_power,
                                             efficiency=0.01,
                                             smoothOperator=None,
                                             smoothPowerIts=1, smoothDepoIts=1, smoothLowIts=3 ):

        &#34;&#34;&#34;
        Function of the SurfaceProcessMesh which computes stream-power erosion and deposition rates
        from a given rainfall pattern (self.rainfall_pattern).

        In this model we assume a the carrying capacity of the stream is related to the stream power and so is the
        erosion rate. The two are related to one another in this particular case by a single contant (everywhere on the mesh)
        This does not allow for spatially variable erodability and it does not allow for differences in the dependence
        of erosion / deposition on the stream power.

        Deposition occurs such that the upstream-integrated eroded sediment does not exceed the carrying capacity at a given
        point. To conserve mass, we have to treat internal drainage points carefully and, optionally, smooth the deposition
        upstream of the low point. We also have to be careful when stream-power and carrying capacity increase going downstream.
        This produces a negative deposition rate when the flow is at capacity. We suppress this behaviour and balance mass across
        all other deposition sites but this does mean the capacity is not perfectly satisfied everywhere.

        parameters:
         efficiency=0.01          : erosion rate for a given stream power compared to carrying capacity
         smoothOperator=None      :
         smoothPowerIts=1         : Use smoothing function (smoothOperator) n times on stream power
         smoothDepoIts=1          : Use smoothing function (smoothOperator) n times on deposition rate
         smoothLowIts=1           : Use smoothing function (smoothOperator) n times on low point patches
        &#34;&#34;&#34;


        if smooth_operator == None:
            smooth_operator = self.rbf_smoother

        for i in range(0, smoothPowerIts):
            stream_power = smoothOperator(stream_power)

        dhdt_erosion = efficiency*stream_power

        cumulative_eroded_material = self.cumulative_flow(erosion_rate*self.area)
        full_capacity_sediment_load = stream_power   # Constant ?

        # if the sediment load exceeds the capacity, start depositing material
        # use vec.pointwisemin
        transport_limited_eroded_material = np.minimum(cumulative_eroded_material, full_capacity_sediment_load)

        excess = sp.gvec.duplicate()
        excess.setArray(cumulative_eroded_material - transport_limited_eroded_material)

        deposition = excess - self.downhillMat*excess
        depo_sum   = deposition.sum()




        # Now rebalance the fact that we have clipped off the negative deposition which will need
        # to be clawed back downstream (ideally, but for now we can just make a global correction)

        deposition = np.clip(deposition.array, 0.0, 1.0e99)
        deposition *= depo_sum / (depo_sum + 1e-12)


        # The (interior) low points are a bit of a problem - we stomped on the stream power there
        # but this produces a very lumpy deposition at the low point itself and this could (does)
        # make the numerical representation pretty unstable. Instead what we can do is to take that
        # deposition at the low points let it spill into the local area


        ## These will instead be handled by a specific routine &#34;handle_low_points&#34; which is
        ## done once the height has been updated

        if len(self.low_points):
            deposition[self.low_points] = 0.0

        # The flat regions in the domain are also problematic since the deposition there is

        flat_spots = self.identify_flat_spots()

        if len(flat_spots):
            smoothed_deposition = deposition.copy()
            smoothed_deposition[np.invert(flat_spots)] = 0.0
            smoothed_deposition = self.local_area_smoothing(smoothed_deposition, its=2, centre_weight=0.5)
            deposition[flat_spots] = smoothed_deposition[flat_spots]

        deposition_rate = smooth_operator(deposition, smooth_deposition_rate, centre_weight=centre_weight) / self.area

        return erosion_rate, deposition_rate, stream_power</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh"><code class="flex name class">
<span>class <span class="ident">SurfMesh</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SurfMesh(_TopoMesh):

    def __init__(self, *args, **kwargs):
        super(SurfMesh,self).__init__(*args, **kwargs)

        # self.kappa = 1.0 # dummy value

        ## Variables that are needed by default methods

        # self.rainfall_pattern_Variable = self.add_variable(name=&#34;precipitation&#34;)
        # self.sediment_distribution_Variable = self.add_variable(name=&#34;sediment&#34;)

        # new context manager ...
        self.deform_topography = self._height_update_context_manager_generator()
        self.upstream_area     = self.add_variable(name=&#34;A(x,y)&#34;, locked=True)

    ## Not sure if it is best to inherit this manager and extend it or to
    ## redefine / over-ride it. Only the exit method has changed.

    def _height_update_context_manager_generator(self):
        &#34;&#34;&#34;Builds a context manager on the current object to control when matrices are to be updated&#34;&#34;&#34;

        surfmesh = self
        topographyVariable = self.topography

        class Surfmesh_Height_Update_Manager(object):
            &#34;&#34;&#34;Manage when changes to the height information trigger a rebuild
            of the topomesh matrices and other internal data.
            &#34;&#34;&#34;

            def __init__(inner_self):
                inner_self.surfmesh = surfmesh
                inner_self._topovar  = topographyVariable
                return

            def __enter__(inner_self):
                # unlock
                inner_self._topovar.unlock()
                return

            def __exit__(inner_self, *args):
                inner_self.surfmesh._update_height()
                inner_self.surfmesh._update_height_for_surface_flows()
                inner_self._topovar.lock()
                return

        return Surfmesh_Height_Update_Manager


    def _update_height_for_surface_flows(self):

        from time import clock
        #self.rainfall_pattern = rainfall_pattern.copy()
        #self.sediment_distribution = sediment_distribution.copy()

        t = perf_counter()

        self.upstream_area.unlock()
        self.upstream_area.data = self.cumulative_flow(self.area)
        self.upstream_area.lock()

        self.timings[&#39;Upstream area&#39;] = [perf_counter()-t, self.log.getCPUTime(), self.log.getFlops()]

        if self.verbose:
            print((&#34;{} - Build upstream areas {}s&#34;.format(self.dm.comm.rank, perf_counter()-t)))

        # Find low points
        self.low_points = self.identify_low_points()

        # Find high points
        self.outflow_points = self.identify_outflow_points()



    def low_points_local_flood_fill(self, its=99999, scale=1.0, smoothing_steps=2):
        &#34;&#34;&#34;
        Fill low points with a local flooding algorithm.
          - its is the number of uphill propagation steps
          - scale
        &#34;&#34;&#34;

        t = perf_counter()
        if self.rank==0 and self.verbose:
            print(&#34;Low point local flood fill&#34;)

        my_low_points = self.identify_low_points()

        self.topography.unlock()
        h = self.topography.data

        fill_height =  (h[self.neighbour_cloud[my_low_points,1:7]].mean(axis=1)-h[my_low_points])

        new_h = self.uphill_propagation(my_low_points,  fill_height, scale=scale,  its=its, fill=0.0)
        new_h = self.sync(new_h)

        smoothed_new_height = self.rbf_smoother(new_h, iterations=smoothing_steps)
        self.topography.data = np.maximum(0.0, smoothed_new_height) + h
        self.topography.sync()
        self.topography.lock()
        self._update_height()

        if self.rank==0 and self.verbose:
            print(&#34;Low point local flood fill &#34;,  perf_counter()-t, &#34; seconds&#34;)

        self._update_height_for_surface_flows()

        return

    def low_points_local_patch_fill(self, its=1, smoothing_steps=1):

        from petsc4py import PETSc
        t = perf_counter()
        if self.rank==0 and self.verbose:
            print(&#34;Low point local patch fill&#34;)

        for iteration in range(0,its):
            low_points = self.identify_low_points()

            self.topography.unlock()

            h = self.topography.data
            delta_height = np.zeros_like(h)

            ## Note, the smoother has a communication barrier so needs to be called even if it has no work to do on this process

            if len(low_points) != 0:
                delta_height[low_points] =  (h[self.neighbour_cloud[low_points,1:5]].mean(axis=1) -
                                                         h[low_points])
            ## Note, the smoother has a communication barrier so needs to be called even
            ## if len(low_points==0) and there is no work to do on this process
            smoothed_height = self.rbf_smoother(h+delta_height, iterations=smoothing_steps)

            self.topography.data = np.maximum(smoothed_height, h)
            self.topography.sync()
            self.topography.lock()
            self._update_height()

        if self.rank==0 and self.verbose:
            print(&#34;Low point local patch fill &#34;,  perf_counter()-t, &#34; seconds&#34;)

        ## and now we need to rebuild the surface process information
        self._update_height_for_surface_flows()

        return


    def low_points_swamp_fill(self, its=1000, saddles=True, ref_height=0.0):

        import petsc4py
        from petsc4py import PETSc
        from mpi4py import MPI

        comm = MPI.COMM_WORLD
        size = comm.Get_size()
        rank = comm.Get_rank()

        t0 = perf_counter()

        my_low_points = self.identify_low_points()
        my_glow_points = self.lgmap_row.apply(my_low_points.astype(PETSc.IntType))


        t = perf_counter()
        ctmt = self.uphill_propagation(my_low_points,  my_glow_points, its=its, fill=-999999).astype(np.int)

        if self.rank==0 and self.verbose:
            print(&#34;Build low point catchments - &#34;, perf_counter() - t, &#34; seconds&#34;)

        if saddles:  # Find saddle points on the catchment edge
            cedges = np.where(ctmt[self.down_neighbour[2]] != ctmt )[0] ## local numbering
        else:        # Fine all edge points
            ctmt2 = ctmt[self.neighbour_cloud] - ctmt.reshape(-1,1)
            ctmt3 = ctmt2 * self.near_neighbour_mask
            cedges = np.where(ctmt3.any(axis=1))[0]

        outer_edges = np.where(~self.bmask)[0]
        edges = np.unique(np.hstack((cedges,outer_edges)))

        height = self.topography.data.copy()

        ## In parallel this is all the low points where this process may have a spill-point
        my_catchments = np.unique(ctmt)

        spills = np.empty((edges.shape[0]),
                         dtype=np.dtype([(&#39;c&#39;, int), (&#39;h&#39;, float), (&#39;x&#39;, float), (&#39;y&#39;, float)]))

        ii = 0
        for l, this_low in enumerate(my_catchments):
            this_low_spills = edges[np.where(ctmt[edges] == this_low)]  ## local numbering

            for spill in this_low_spills:
                spills[&#39;c&#39;][ii] = this_low
                spills[&#39;h&#39;][ii] = height[spill]
                spills[&#39;x&#39;][ii] = self.coords[spill,0]
                spills[&#39;y&#39;][ii] = self.coords[spill,1]
                ii += 1

        t = perf_counter()

        spills.sort(axis=0)  # Sorts by catchment then height ...
        s, indices = np.unique(spills[&#39;c&#39;], return_index=True)
        spill_points = spills[indices]

        if self.rank == 0 and self.verbose:
            print(self.rank, &#34; Sort spills - &#34;, perf_counter() - t)

        # Gather lists to process 0, stack and remove duplicates

        t = perf_counter()
        list_of_spills = comm.gather(spill_points,   root=0)

        if self.rank == 0 and self.verbose:
            print(self.rank, &#34; Gather spill data - &#34;, perf_counter() - t)

        if self.rank == 0:
            t = perf_counter()

            all_spills = np.hstack(list_of_spills)
            all_spills.sort(axis=0) # Sorts by catchment then height ...
            s, indices = np.unique(all_spills[&#39;c&#39;], return_index=True)
            all_spill_points = all_spills[indices]

            if self.verbose:
                print(rank, &#34; Sort all spills - &#34;, perf_counter() - t)

        else:
            all_spill_points = None
            pass

        # Broadcast lists to everyone

        global_spill_points = comm.bcast(all_spill_points, root=0)

        height2 = np.zeros_like(height) + ref_height

        for i, spill in enumerate(global_spill_points):
            this_catchment = int(spill[&#39;c&#39;])

            ## -ve values indicate that the point is connected
            ## to the outflow of the mesh and needs no modification
            if this_catchment &lt; 0:
                continue

            catchment_nodes = np.where(ctmt == this_catchment)
            separation_x = (self.coords[catchment_nodes,0] - spill[&#39;x&#39;])
            separation_y = (self.coords[catchment_nodes,1] - spill[&#39;y&#39;])
            distance = np.hypot(separation_x, separation_y)

            height2[catchment_nodes] = spill[&#39;h&#39;] + 0.000001 * distance  # A &#39;small&#39; gradient (should be a user-parameter)

        height2 = self.sync(height2)

        new_height = np.maximum(height, height2)
        new_height = self.sync(new_height)


        # We only need to update the height not all
        # surface process information that is associated with it.
        self.topography.unlock()
        self.topography.data = new_height
        self._update_height()
        self.topography.lock()


        if self.rank==0 and self.verbose:
            print(&#34;Low point swamp fill &#34;,  perf_counter()-t0, &#34; seconds&#34;)

        ## but now we need to rebuild the surface process information
        self._update_height_for_surface_flows()
        return


    def backfill_points(self, fill_points, heights, its):
        &#34;&#34;&#34;
        Handles *selected* low points by backfilling height array.
        This can be used to block a stream path, for example, or to locate lakes
        &#34;&#34;&#34;

        if len(fill_points) == 0:
            return self.heightVariable.data

        new_height = self.lvec.duplicate()
        new_height.setArray(heights)
        height = np.maximum(self.height, new_height.array)

        # Now march the new height to all the uphill nodes of these nodes
        # height = np.maximum(self.height, delta_height.array)

        self.dm.localToGlobal(new_height, self.gvec)
        global_dH = self.gvec.copy()

        for p in range(0, its):
            self.adjacency[1].multTranspose(global_dH, self.gvec)
            global_dH.setArray(self.gvec)
            global_dH.scale(1.001)  # Maybe !
            self.dm.globalToLocal(global_dH, new_height)

            height = np.maximum(height, new_height.array)

        return height

    def uphill_propagation(self, points, values, scale=1.0, its=1000, fill=-1):

        t0 = perf_counter()

        local_ID = self.lvec.copy()
        global_ID = self.gvec.copy()

        local_ID.set(fill+1)
        global_ID.set(fill+1)

        identifier = np.empty_like(self.topography.data)
        identifier.fill(fill+1)

        if len(points):
            identifier[points] = values + 1

        local_ID.setArray(identifier)
        self.dm.localToGlobal(local_ID, global_ID)

        delta = global_ID.copy()
        delta.abs()
        rtolerance = delta.max()[1] * 1.0e-10

        for p in range(0, its):

            # self.adjacency[1].multTranspose(global_ID, self.gvec)
            gvec = self.uphill[1] * global_ID
            delta = global_ID - gvec
            delta.abs()
            max_delta = delta.max()[1]

            if max_delta &lt; rtolerance:
                break

            self.gvec.scale(scale)

            if self.dm.comm.Get_size() == 1:
                local_ID.array[:] = gvec.array[:]
            else:
                self.dm.globalToLocal(gvec, local_ID)

            global_ID.array[:] = gvec.array[:]

            identifier = np.maximum(identifier, local_ID.array)
            identifier = self.sync(identifier)

        # Note, the -1 is used to identify out of bounds values

        if self.rank == 0 and self.verbose:
            print(p, &#34; iterations, time = &#34;, perf_counter() - t0)

        return identifier - 1



    def identify_low_points(self, include_shadows=False):
        &#34;&#34;&#34;
        Identify if the mesh has (internal) local minima and return an array of node indices
        &#34;&#34;&#34;

        # from petsc4py import PETSc

        nodes = np.arange(0, self.npoints, dtype=np.int)
        gnodes = self.lgmap_row.apply(nodes.astype(PETSc.IntType))

        low_nodes = self.down_neighbour[1]
        mask = np.logical_and(nodes == low_nodes, self.bmask == True)

        if not include_shadows:
            mask = np.logical_and(mask, gnodes &gt;= 0)

        return nodes[mask]

    def identify_global_low_points(self, global_array=False):
        &#34;&#34;&#34;
        Identify if the mesh as a whole has (internal) local minima and return an array of local lows in global
        index format.

        If global_array is True, then lows for the whole mesh are returned
        &#34;&#34;&#34;

        import petsc4py
        from petsc4py import PETSc
        from mpi4py import MPI

        comm = MPI.COMM_WORLD
        size = comm.Get_size()
        rank = comm.Get_rank()

        # from petsc4py import PETSc

        nodes = np.arange(0, self.npoints, dtype=np.int)
        gnodes = self.lgmap_row.apply(nodes.astype(PETSc.IntType))

        low_nodes = self.down_neighbour[1]
        mask = np.logical_and(nodes == low_nodes, self.bmask == True)
        mask = np.logical_and(mask, gnodes &gt;= 0)

        number_of_lows = np.count_nonzero(mask)
        low_gnodes = self.lgmap_row.apply(low_nodes.astype(PETSc.IntType))

        # gather/scatter numbers

        list_of_nlows  = comm.gather(number_of_lows,   root=0)
        if self.rank == 0:
            all_low_counts = np.hstack(list_of_nlows)
            no_global_lows0 = all_low_counts.sum()

        else:
            no_global_lows0 = None

        no_global_lows = comm.bcast(no_global_lows0, root=0)


        if global_array:

            list_of_lglows = comm.gather(low_gnodes,   root=0)

            if self.rank == 0:
                all_glows = np.hstack(list_of_lglows)
                global_lows0 = np.unique(all_glows)

            else:
                global_lows0 = None

            low_gnodes = comm.bcast(global_lows0, root=0)

        return no_global_lows, low_gnodes


    def identify_outflow_points(self):
        &#34;&#34;&#34;
        Identify the (boundary) outflow points and return an array of (local) node indices
        &#34;&#34;&#34;

        # nodes = np.arange(0, self.npoints, dtype=np.int)
        # low_nodes = self.down_neighbour[1]
        # mask = np.logical_and(nodes == low_nodes, self.bmask == False)
        #

        i = self.downhill_neighbours

        o = (np.logical_and(self.down_neighbour[i] == np.indices(self.down_neighbour[i].shape), self.bmask == False)).ravel()
        outflow_nodes = o.nonzero()[0]

        return outflow_nodes


    def identify_flat_spots(self):

        slope = self.slope.evaluate(self.slope._mesh)
        smooth_grad1 = self.local_area_smoothing(slope, its=1, centre_weight=0.5)

        # flat_spot_field = np.where(smooth_grad1 &lt; smooth_grad1.max()/100, 0.0, 1.0)

        flat_spots = np.where(smooth_grad1 &lt; smooth_grad1.max()/1000.0, True, False)

        return flat_spots


    def stream_power_erosion_deposition_rate_old(self, efficiency=0.01, smooth_power=3, \
                                             smooth_low_points=2, smooth_erosion_rate=2, \
                                             smooth_deposition_rate=2, smooth_operator=None,
                                             centre_weight_u=0.5, centre_weight=0.5):

        &#34;&#34;&#34;
        Function of the SurfaceProcessMesh which computes stream-power erosion and deposition rates
        from a given rainfall pattern (self.rainfall_pattern).

        In this model we assume a the carrying capacity of the stream is related to the stream power and so is the
        erosion rate. The two are related to one another in this particular case by a single contant (everywhere on the mesh)
        This does not allow for spatially variable erodability and it does not allow for differences in the dependence
        of erosion / deposition on the stream power.

        Deposition occurs such that the upstream-integrated eroded sediment does not exceed the carrying capacity at a given
        point. To conserve mass, we have to treat internal drainage points carefully and, optionally, smooth the deposition
        upstream of the low point. We also have to be careful when stream-power and carrying capacity increase going downstream.
        This produces a negative deposition rate when the flow is at capacity. We suppress this behaviour and balance mass across
        all other deposition sites but this does mean the capacity is not perfectly satisfied everywhere.

        parameters:
         efficiency=0.01          : erosion rate for a given stream power compared to carrying capacity
         smooth_power=3           : upstream / downstream smoothing of the stream power (number of cycles of smoothing)
         smooth_low_points=3      : upstream smoothing of the deposition at low points (number of cycles of smoothing)
         smooth_erosion_rate=0    : upstream / downstream smoothing of the computed erosion rate (number of cycles of smoothing)
         smooth_deposition_rate=0 : upstream / downstream smoothing of the computed erosion rate (number of cycles of smoothing)

        &#34;&#34;&#34;


        if smooth_operator == None:
            smooth_operator = self.streamwise_smoothing

        # Calculate stream power

        ## Model 1 - Local equilibrium

        rainflux = self.rainfall_pattern
        rainfall = self.area * rainflux
        cumulative_rain = self.cumulative_flow(rainfall)

        cumulative_flow_rate = cumulative_rain / self.area

        stream_power = self.uphill_smoothing(cumulative_flow_rate * self.slopeVariable.data, smooth_power, centre_weight=centre_weight_u)

        #  predicted erosion rate from stream power * efficiency
        #  maximum sediment that can be transported is limited by the local carrying capacity (assume also prop to stream power)
        #  whatever cannot be passed on has to be deposited

        erosion_rate = self.streamwise_smoothing(efficiency * stream_power, smooth_erosion_rate, centre_weight=centre_weight)
        full_capacity_sediment_flux = stream_power
        full_capacity_sediment_load = stream_power * self.area
        cumulative_eroded_material = self.cumulative_flow(self.area * erosion_rate)

        # But this can exceed the carrying capacity

        transport_limited_eroded_material = np.minimum(cumulative_eroded_material, full_capacity_sediment_load)
        transport_limited_erosion_rate = transport_limited_eroded_material / self.area

        # And this therefore implies a deposition rate which reduces the total sediment in the system to capacity
        # Calculate this by substracting the deposited amounts from the excess integrated flow. We could then iterate
        # to compute the new erosion rates etc, but here we just spread the sediments around to places where
        # the deposition is positive

        excess = self.gvec.duplicate()
        deposition = self.lvec.duplicate()
        self.lvec.setArray(cumulative_eroded_material - transport_limited_eroded_material)
        self.dm.localToGlobal(self.lvec, excess)
        self.downhillMat.mult(excess, self.gvec)
        self.dm.globalToLocal(excess - self.gvec, deposition)
        depo_sum = deposition.sum()


        # Now rebalance the fact that we have clipped off the negative deposition which will need
        # to be clawed back downstream (ideally, but for now we can just make a global correction)

        deposition = np.clip(deposition.array, 0.0, 1.0e99)
        deposition *= depo_sum / (depo_sum + 1e-12)


        # The (interior) low points are a bit of a problem - we stomped on the stream power there
        # but this produces a very lumpy deposition at the low point itself and this could (does)
        # make the numerical representation pretty unstable. Instead what we can do is to take that
        # deposition at the low points let it spill into the local area


        ## These will instead be handled by a specific routine &#34;handle_low_points&#34; which is
        ## done once the height has been updated

        if len(self.low_points):
            deposition[self.low_points] = 0.0

        # The flat regions in the domain are also problematic since the deposition there is

        flat_spots = self.identify_flat_spots()

        if len(flat_spots):
            smoothed_deposition = deposition.copy()
            smoothed_deposition[np.invert(flat_spots)] = 0.0
            smoothed_deposition = self.local_area_smoothing(smoothed_deposition, its=2, centre_weight=0.5)
            deposition[flat_spots] = smoothed_deposition[flat_spots]

        deposition_rate = smooth_operator(deposition, smooth_deposition_rate, centre_weight=centre_weight) / self.area

        return erosion_rate, deposition_rate, stream_power



    # def landscape_diffusion_critical_slope(self, kappa, critical_slope, fluxBC):
    #     &#39;&#39;&#39;
    #     Non-linear diffusion to keep slopes at a critical value. Assumes a background
    #     diffusion rate (can be a vector of length mesh.tri.npoints) and a critical slope value.
    #
    #     This term is suitable for the sloughing of sediment from hillslopes.
    #
    #     To Do: The critical slope should be a function of the material (sediment, basement etc)
    #     but currently it is not.
    #
    #     To Do: The fluxBC flag is global ... it should apply to the outward normal
    #     at selected nodes but currently it is set to kill both fluxes at all boundary nodes.
    #     &#39;&#39;&#39;
    #
    #     inverse_bmask = np.invert(self.bmask)
    #
    #     kappa_eff = kappa / (1.01 - (np.clip(self.slopeVariable.data,0.0,critical_slope) / critical_slope)**2)
    #     self.kappa = kappa_eff
    #
    #     # get minimum timestep across the global mesh
    #     local_diffusion_timestep = np.array((self.area / kappa_eff).min())
    #     global_diffusion_timestep = np.array(0.0)
    #     self.comm.Allreduce([local_diffusion_timestep, MPI.DOUBLE], \
    #                         [global_diffusion_timestep, MPI.DOUBLE], op=MPI.MIN)
    #
    #
    #     fluxVariable = self.heightVariable.gradient(nit=3, tol=1e-3)
    #     fluxVariable.data *= kappa_eff.reshape(-1,1)
    #     if fluxBC:
    #         fluxVariable.data[inverse_bmask] = 0.0 # outward normal flux, actually
    #
    #     diffDz = self.derivative_div(*fluxVariable.data.T, nit=3, tol=1e-3)
    #     diffDz = self.sync(diffDz)
    #
    #     if not fluxBC:
    #         diffDz[inverse_bmask] = 0.0
    #
    #     return diffDz, global_diffusion_timestep
    #


    def landscape_diffusion_critical_slope(self, kappa, critical_slope, fluxBC):
        &#39;&#39;&#39;
        Non-linear diffusion to keep slopes at a critical value. Assumes a background
        diffusion rate (can be a vector of length mesh.tri.npoints) and a critical slope value.
        This term is suitable for the sloughing of sediment from hillslopes.
        To Do: The critical slope should be a function of the material (sediment, basement etc)
        but currently it is not.
        To Do: The fluxBC flag is global ... it should apply to the outward normal
        at selected nodes but currently it is set to kill both fluxes at all boundary nodes.
        &#39;&#39;&#39;

        inverse_bmask = np.invert(self.bmask)

        kappa_eff = kappa / (1.01 - (np.clip(self.slopeVariable.data,0.0,critical_slope) / critical_slope)**2)
        self.kappa = kappa_eff
        # diff_timestep   =  self.area.min() / kappa_eff.max()

        # get minimum timestep across the global mesh
        local_diffusion_timestep = np.array((self.area / kappa_eff).min())
        global_diffusion_timestep = np.array(1e24)
        self.comm.Allreduce([local_diffusion_timestep, MPI.DOUBLE], \
                            [global_diffusion_timestep, MPI.DOUBLE], op=MPI.MIN)


        gradZx, gradZy = self.derivative_grad(self.topography.data)
        gradZx = self.sync(gradZx)
        gradZy = self.sync(gradZy)
        flux_x = kappa_eff * gradZx
        flux_y = kappa_eff * gradZy

        if fluxBC:
            flux_x[inverse_bmask] = 0.0
            flux_y[inverse_bmask] = 0.0  # outward normal flux, actually

        diffDz = self.derivative_div(flux_x, flux_y)
        diffDz = self.sync(diffDz)

        if not fluxBC:
            diffDz[inverse_bmask] = 0.0

        return diffDz, global_diffusion_timestep



    def landscape_evolution_timestep(self, diffusion_rate, erosion_rate, deposition_rate, uplift_rate):
        &#34;&#34;&#34;
        Calculate the change in topography for one timestep
        &#34;&#34;&#34;

        time = 0.0
        typical_l = np.sqrt(self.area)
        critical_slope = 50.0

        slope = np.maximum(self.slopeVariable.data, critical_slope)

        erosion_deposition_rate = deposition_rate - erosion_rate

        erosion_timestep    = (self.slopeVariable.data*typical_l/(erosion_rate + 1e-12)).min()
        deposition_timestep = (self.slopeVariable.data*typical_l/(deposition_rate + 1e-12)).min()
        diffusion_timestep  = self.area.min()/np.max(self.kappa)

        local_timestep = np.array(min(erosion_timestep, deposition_timestep, diffusion_timestep))
        timestep = np.array(0.0)
        comm.Allreduce([local_timestep, MPI.DOUBLE], [timestep, MPI.DOUBLE], op=MPI.MIN)

        delta_h = timestep * (erosion_deposition_rate - diffusion_rate + uplift_rate)

        # Note this is based on local information, and must be synced
        return delta_h, timestep




    def stream_power_erosion_deposition_rate_local(self, stream_power,
                                             efficiency=0.01,
                                             smoothOperator=None,
                                             smoothPowerIts=1, smoothDepoIts=1, smoothLowIts=3 ):

        &#34;&#34;&#34;
        Function of the SurfaceProcessMesh which computes stream-power erosion and deposition rates
        from a given rainfall pattern (self.rainfall_pattern).

        In this model we assume a the carrying capacity of the stream is related to the stream power and so is the
        erosion rate. The two are related to one another in this particular case by a single contant (everywhere on the mesh)
        This does not allow for spatially variable erodability and it does not allow for differences in the dependence
        of erosion / deposition on the stream power.

        Deposition occurs such that the upstream-integrated eroded sediment does not exceed the carrying capacity at a given
        point. To conserve mass, we have to treat internal drainage points carefully and, optionally, smooth the deposition
        upstream of the low point. We also have to be careful when stream-power and carrying capacity increase going downstream.
        This produces a negative deposition rate when the flow is at capacity. We suppress this behaviour and balance mass across
        all other deposition sites but this does mean the capacity is not perfectly satisfied everywhere.

        parameters:
         efficiency=0.01          : erosion rate for a given stream power compared to carrying capacity
         smoothOperator=None      :
         smoothPowerIts=1         : Use smoothing function (smoothOperator) n times on stream power
         smoothDepoIts=1          : Use smoothing function (smoothOperator) n times on deposition rate
         smoothLowIts=1           : Use smoothing function (smoothOperator) n times on low point patches
        &#34;&#34;&#34;


        if smooth_operator == None:
            smooth_operator = self.rbf_smoother

        for i in range(0, smoothPowerIts):
            stream_power = smoothOperator(stream_power)

        dhdt_erosion = efficiency*stream_power

        cumulative_eroded_material = self.cumulative_flow(erosion_rate*self.area)
        full_capacity_sediment_load = stream_power   # Constant ?

        # if the sediment load exceeds the capacity, start depositing material
        # use vec.pointwisemin
        transport_limited_eroded_material = np.minimum(cumulative_eroded_material, full_capacity_sediment_load)

        excess = sp.gvec.duplicate()
        excess.setArray(cumulative_eroded_material - transport_limited_eroded_material)

        deposition = excess - self.downhillMat*excess
        depo_sum   = deposition.sum()




        # Now rebalance the fact that we have clipped off the negative deposition which will need
        # to be clawed back downstream (ideally, but for now we can just make a global correction)

        deposition = np.clip(deposition.array, 0.0, 1.0e99)
        deposition *= depo_sum / (depo_sum + 1e-12)


        # The (interior) low points are a bit of a problem - we stomped on the stream power there
        # but this produces a very lumpy deposition at the low point itself and this could (does)
        # make the numerical representation pretty unstable. Instead what we can do is to take that
        # deposition at the low points let it spill into the local area


        ## These will instead be handled by a specific routine &#34;handle_low_points&#34; which is
        ## done once the height has been updated

        if len(self.low_points):
            deposition[self.low_points] = 0.0

        # The flat regions in the domain are also problematic since the deposition there is

        flat_spots = self.identify_flat_spots()

        if len(flat_spots):
            smoothed_deposition = deposition.copy()
            smoothed_deposition[np.invert(flat_spots)] = 0.0
            smoothed_deposition = self.local_area_smoothing(smoothed_deposition, its=2, centre_weight=0.5)
            deposition[flat_spots] = smoothed_deposition[flat_spots]

        deposition_rate = smooth_operator(deposition, smooth_deposition_rate, centre_weight=centre_weight) / self.area

        return erosion_rate, deposition_rate, stream_power</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="quagmire.topomesh.topomesh.TopoMesh" href="../topomesh/topomesh.html#quagmire.topomesh.topomesh.TopoMesh">TopoMesh</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.backfill_points"><code class="name flex">
<span>def <span class="ident">backfill_points</span></span>(<span>self, fill_points, heights, its)</span>
</code></dt>
<dd>
<div class="desc"><p>Handles <em>selected</em> low points by backfilling height array.
This can be used to block a stream path, for example, or to locate lakes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def backfill_points(self, fill_points, heights, its):
    &#34;&#34;&#34;
    Handles *selected* low points by backfilling height array.
    This can be used to block a stream path, for example, or to locate lakes
    &#34;&#34;&#34;

    if len(fill_points) == 0:
        return self.heightVariable.data

    new_height = self.lvec.duplicate()
    new_height.setArray(heights)
    height = np.maximum(self.height, new_height.array)

    # Now march the new height to all the uphill nodes of these nodes
    # height = np.maximum(self.height, delta_height.array)

    self.dm.localToGlobal(new_height, self.gvec)
    global_dH = self.gvec.copy()

    for p in range(0, its):
        self.adjacency[1].multTranspose(global_dH, self.gvec)
        global_dH.setArray(self.gvec)
        global_dH.scale(1.001)  # Maybe !
        self.dm.globalToLocal(global_dH, new_height)

        height = np.maximum(height, new_height.array)

    return height</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.identify_flat_spots"><code class="name flex">
<span>def <span class="ident">identify_flat_spots</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_flat_spots(self):

    slope = self.slope.evaluate(self.slope._mesh)
    smooth_grad1 = self.local_area_smoothing(slope, its=1, centre_weight=0.5)

    # flat_spot_field = np.where(smooth_grad1 &lt; smooth_grad1.max()/100, 0.0, 1.0)

    flat_spots = np.where(smooth_grad1 &lt; smooth_grad1.max()/1000.0, True, False)

    return flat_spots</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.identify_global_low_points"><code class="name flex">
<span>def <span class="ident">identify_global_low_points</span></span>(<span>self, global_array=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Identify if the mesh as a whole has (internal) local minima and return an array of local lows in global
index format.</p>
<p>If global_array is True, then lows for the whole mesh are returned</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_global_low_points(self, global_array=False):
    &#34;&#34;&#34;
    Identify if the mesh as a whole has (internal) local minima and return an array of local lows in global
    index format.

    If global_array is True, then lows for the whole mesh are returned
    &#34;&#34;&#34;

    import petsc4py
    from petsc4py import PETSc
    from mpi4py import MPI

    comm = MPI.COMM_WORLD
    size = comm.Get_size()
    rank = comm.Get_rank()

    # from petsc4py import PETSc

    nodes = np.arange(0, self.npoints, dtype=np.int)
    gnodes = self.lgmap_row.apply(nodes.astype(PETSc.IntType))

    low_nodes = self.down_neighbour[1]
    mask = np.logical_and(nodes == low_nodes, self.bmask == True)
    mask = np.logical_and(mask, gnodes &gt;= 0)

    number_of_lows = np.count_nonzero(mask)
    low_gnodes = self.lgmap_row.apply(low_nodes.astype(PETSc.IntType))

    # gather/scatter numbers

    list_of_nlows  = comm.gather(number_of_lows,   root=0)
    if self.rank == 0:
        all_low_counts = np.hstack(list_of_nlows)
        no_global_lows0 = all_low_counts.sum()

    else:
        no_global_lows0 = None

    no_global_lows = comm.bcast(no_global_lows0, root=0)


    if global_array:

        list_of_lglows = comm.gather(low_gnodes,   root=0)

        if self.rank == 0:
            all_glows = np.hstack(list_of_lglows)
            global_lows0 = np.unique(all_glows)

        else:
            global_lows0 = None

        low_gnodes = comm.bcast(global_lows0, root=0)

    return no_global_lows, low_gnodes</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.identify_low_points"><code class="name flex">
<span>def <span class="ident">identify_low_points</span></span>(<span>self, include_shadows=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Identify if the mesh has (internal) local minima and return an array of node indices</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_low_points(self, include_shadows=False):
    &#34;&#34;&#34;
    Identify if the mesh has (internal) local minima and return an array of node indices
    &#34;&#34;&#34;

    # from petsc4py import PETSc

    nodes = np.arange(0, self.npoints, dtype=np.int)
    gnodes = self.lgmap_row.apply(nodes.astype(PETSc.IntType))

    low_nodes = self.down_neighbour[1]
    mask = np.logical_and(nodes == low_nodes, self.bmask == True)

    if not include_shadows:
        mask = np.logical_and(mask, gnodes &gt;= 0)

    return nodes[mask]</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.identify_outflow_points"><code class="name flex">
<span>def <span class="ident">identify_outflow_points</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Identify the (boundary) outflow points and return an array of (local) node indices</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_outflow_points(self):
    &#34;&#34;&#34;
    Identify the (boundary) outflow points and return an array of (local) node indices
    &#34;&#34;&#34;

    # nodes = np.arange(0, self.npoints, dtype=np.int)
    # low_nodes = self.down_neighbour[1]
    # mask = np.logical_and(nodes == low_nodes, self.bmask == False)
    #

    i = self.downhill_neighbours

    o = (np.logical_and(self.down_neighbour[i] == np.indices(self.down_neighbour[i].shape), self.bmask == False)).ravel()
    outflow_nodes = o.nonzero()[0]

    return outflow_nodes</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.landscape_diffusion_critical_slope"><code class="name flex">
<span>def <span class="ident">landscape_diffusion_critical_slope</span></span>(<span>self, kappa, critical_slope, fluxBC)</span>
</code></dt>
<dd>
<div class="desc"><p>Non-linear diffusion to keep slopes at a critical value. Assumes a background
diffusion rate (can be a vector of length mesh.tri.npoints) and a critical slope value.
This term is suitable for the sloughing of sediment from hillslopes.
To Do: The critical slope should be a function of the material (sediment, basement etc)
but currently it is not.
To Do: The fluxBC flag is global &hellip; it should apply to the outward normal
at selected nodes but currently it is set to kill both fluxes at all boundary nodes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def landscape_diffusion_critical_slope(self, kappa, critical_slope, fluxBC):
    &#39;&#39;&#39;
    Non-linear diffusion to keep slopes at a critical value. Assumes a background
    diffusion rate (can be a vector of length mesh.tri.npoints) and a critical slope value.
    This term is suitable for the sloughing of sediment from hillslopes.
    To Do: The critical slope should be a function of the material (sediment, basement etc)
    but currently it is not.
    To Do: The fluxBC flag is global ... it should apply to the outward normal
    at selected nodes but currently it is set to kill both fluxes at all boundary nodes.
    &#39;&#39;&#39;

    inverse_bmask = np.invert(self.bmask)

    kappa_eff = kappa / (1.01 - (np.clip(self.slopeVariable.data,0.0,critical_slope) / critical_slope)**2)
    self.kappa = kappa_eff
    # diff_timestep   =  self.area.min() / kappa_eff.max()

    # get minimum timestep across the global mesh
    local_diffusion_timestep = np.array((self.area / kappa_eff).min())
    global_diffusion_timestep = np.array(1e24)
    self.comm.Allreduce([local_diffusion_timestep, MPI.DOUBLE], \
                        [global_diffusion_timestep, MPI.DOUBLE], op=MPI.MIN)


    gradZx, gradZy = self.derivative_grad(self.topography.data)
    gradZx = self.sync(gradZx)
    gradZy = self.sync(gradZy)
    flux_x = kappa_eff * gradZx
    flux_y = kappa_eff * gradZy

    if fluxBC:
        flux_x[inverse_bmask] = 0.0
        flux_y[inverse_bmask] = 0.0  # outward normal flux, actually

    diffDz = self.derivative_div(flux_x, flux_y)
    diffDz = self.sync(diffDz)

    if not fluxBC:
        diffDz[inverse_bmask] = 0.0

    return diffDz, global_diffusion_timestep</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.landscape_evolution_timestep"><code class="name flex">
<span>def <span class="ident">landscape_evolution_timestep</span></span>(<span>self, diffusion_rate, erosion_rate, deposition_rate, uplift_rate)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the change in topography for one timestep</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def landscape_evolution_timestep(self, diffusion_rate, erosion_rate, deposition_rate, uplift_rate):
    &#34;&#34;&#34;
    Calculate the change in topography for one timestep
    &#34;&#34;&#34;

    time = 0.0
    typical_l = np.sqrt(self.area)
    critical_slope = 50.0

    slope = np.maximum(self.slopeVariable.data, critical_slope)

    erosion_deposition_rate = deposition_rate - erosion_rate

    erosion_timestep    = (self.slopeVariable.data*typical_l/(erosion_rate + 1e-12)).min()
    deposition_timestep = (self.slopeVariable.data*typical_l/(deposition_rate + 1e-12)).min()
    diffusion_timestep  = self.area.min()/np.max(self.kappa)

    local_timestep = np.array(min(erosion_timestep, deposition_timestep, diffusion_timestep))
    timestep = np.array(0.0)
    comm.Allreduce([local_timestep, MPI.DOUBLE], [timestep, MPI.DOUBLE], op=MPI.MIN)

    delta_h = timestep * (erosion_deposition_rate - diffusion_rate + uplift_rate)

    # Note this is based on local information, and must be synced
    return delta_h, timestep</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.low_points_local_flood_fill"><code class="name flex">
<span>def <span class="ident">low_points_local_flood_fill</span></span>(<span>self, its=99999, scale=1.0, smoothing_steps=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Fill low points with a local flooding algorithm.
- its is the number of uphill propagation steps
- scale</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def low_points_local_flood_fill(self, its=99999, scale=1.0, smoothing_steps=2):
    &#34;&#34;&#34;
    Fill low points with a local flooding algorithm.
      - its is the number of uphill propagation steps
      - scale
    &#34;&#34;&#34;

    t = perf_counter()
    if self.rank==0 and self.verbose:
        print(&#34;Low point local flood fill&#34;)

    my_low_points = self.identify_low_points()

    self.topography.unlock()
    h = self.topography.data

    fill_height =  (h[self.neighbour_cloud[my_low_points,1:7]].mean(axis=1)-h[my_low_points])

    new_h = self.uphill_propagation(my_low_points,  fill_height, scale=scale,  its=its, fill=0.0)
    new_h = self.sync(new_h)

    smoothed_new_height = self.rbf_smoother(new_h, iterations=smoothing_steps)
    self.topography.data = np.maximum(0.0, smoothed_new_height) + h
    self.topography.sync()
    self.topography.lock()
    self._update_height()

    if self.rank==0 and self.verbose:
        print(&#34;Low point local flood fill &#34;,  perf_counter()-t, &#34; seconds&#34;)

    self._update_height_for_surface_flows()

    return</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.low_points_local_patch_fill"><code class="name flex">
<span>def <span class="ident">low_points_local_patch_fill</span></span>(<span>self, its=1, smoothing_steps=1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def low_points_local_patch_fill(self, its=1, smoothing_steps=1):

    from petsc4py import PETSc
    t = perf_counter()
    if self.rank==0 and self.verbose:
        print(&#34;Low point local patch fill&#34;)

    for iteration in range(0,its):
        low_points = self.identify_low_points()

        self.topography.unlock()

        h = self.topography.data
        delta_height = np.zeros_like(h)

        ## Note, the smoother has a communication barrier so needs to be called even if it has no work to do on this process

        if len(low_points) != 0:
            delta_height[low_points] =  (h[self.neighbour_cloud[low_points,1:5]].mean(axis=1) -
                                                     h[low_points])
        ## Note, the smoother has a communication barrier so needs to be called even
        ## if len(low_points==0) and there is no work to do on this process
        smoothed_height = self.rbf_smoother(h+delta_height, iterations=smoothing_steps)

        self.topography.data = np.maximum(smoothed_height, h)
        self.topography.sync()
        self.topography.lock()
        self._update_height()

    if self.rank==0 and self.verbose:
        print(&#34;Low point local patch fill &#34;,  perf_counter()-t, &#34; seconds&#34;)

    ## and now we need to rebuild the surface process information
    self._update_height_for_surface_flows()

    return</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.low_points_swamp_fill"><code class="name flex">
<span>def <span class="ident">low_points_swamp_fill</span></span>(<span>self, its=1000, saddles=True, ref_height=0.0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def low_points_swamp_fill(self, its=1000, saddles=True, ref_height=0.0):

    import petsc4py
    from petsc4py import PETSc
    from mpi4py import MPI

    comm = MPI.COMM_WORLD
    size = comm.Get_size()
    rank = comm.Get_rank()

    t0 = perf_counter()

    my_low_points = self.identify_low_points()
    my_glow_points = self.lgmap_row.apply(my_low_points.astype(PETSc.IntType))


    t = perf_counter()
    ctmt = self.uphill_propagation(my_low_points,  my_glow_points, its=its, fill=-999999).astype(np.int)

    if self.rank==0 and self.verbose:
        print(&#34;Build low point catchments - &#34;, perf_counter() - t, &#34; seconds&#34;)

    if saddles:  # Find saddle points on the catchment edge
        cedges = np.where(ctmt[self.down_neighbour[2]] != ctmt )[0] ## local numbering
    else:        # Fine all edge points
        ctmt2 = ctmt[self.neighbour_cloud] - ctmt.reshape(-1,1)
        ctmt3 = ctmt2 * self.near_neighbour_mask
        cedges = np.where(ctmt3.any(axis=1))[0]

    outer_edges = np.where(~self.bmask)[0]
    edges = np.unique(np.hstack((cedges,outer_edges)))

    height = self.topography.data.copy()

    ## In parallel this is all the low points where this process may have a spill-point
    my_catchments = np.unique(ctmt)

    spills = np.empty((edges.shape[0]),
                     dtype=np.dtype([(&#39;c&#39;, int), (&#39;h&#39;, float), (&#39;x&#39;, float), (&#39;y&#39;, float)]))

    ii = 0
    for l, this_low in enumerate(my_catchments):
        this_low_spills = edges[np.where(ctmt[edges] == this_low)]  ## local numbering

        for spill in this_low_spills:
            spills[&#39;c&#39;][ii] = this_low
            spills[&#39;h&#39;][ii] = height[spill]
            spills[&#39;x&#39;][ii] = self.coords[spill,0]
            spills[&#39;y&#39;][ii] = self.coords[spill,1]
            ii += 1

    t = perf_counter()

    spills.sort(axis=0)  # Sorts by catchment then height ...
    s, indices = np.unique(spills[&#39;c&#39;], return_index=True)
    spill_points = spills[indices]

    if self.rank == 0 and self.verbose:
        print(self.rank, &#34; Sort spills - &#34;, perf_counter() - t)

    # Gather lists to process 0, stack and remove duplicates

    t = perf_counter()
    list_of_spills = comm.gather(spill_points,   root=0)

    if self.rank == 0 and self.verbose:
        print(self.rank, &#34; Gather spill data - &#34;, perf_counter() - t)

    if self.rank == 0:
        t = perf_counter()

        all_spills = np.hstack(list_of_spills)
        all_spills.sort(axis=0) # Sorts by catchment then height ...
        s, indices = np.unique(all_spills[&#39;c&#39;], return_index=True)
        all_spill_points = all_spills[indices]

        if self.verbose:
            print(rank, &#34; Sort all spills - &#34;, perf_counter() - t)

    else:
        all_spill_points = None
        pass

    # Broadcast lists to everyone

    global_spill_points = comm.bcast(all_spill_points, root=0)

    height2 = np.zeros_like(height) + ref_height

    for i, spill in enumerate(global_spill_points):
        this_catchment = int(spill[&#39;c&#39;])

        ## -ve values indicate that the point is connected
        ## to the outflow of the mesh and needs no modification
        if this_catchment &lt; 0:
            continue

        catchment_nodes = np.where(ctmt == this_catchment)
        separation_x = (self.coords[catchment_nodes,0] - spill[&#39;x&#39;])
        separation_y = (self.coords[catchment_nodes,1] - spill[&#39;y&#39;])
        distance = np.hypot(separation_x, separation_y)

        height2[catchment_nodes] = spill[&#39;h&#39;] + 0.000001 * distance  # A &#39;small&#39; gradient (should be a user-parameter)

    height2 = self.sync(height2)

    new_height = np.maximum(height, height2)
    new_height = self.sync(new_height)


    # We only need to update the height not all
    # surface process information that is associated with it.
    self.topography.unlock()
    self.topography.data = new_height
    self._update_height()
    self.topography.lock()


    if self.rank==0 and self.verbose:
        print(&#34;Low point swamp fill &#34;,  perf_counter()-t0, &#34; seconds&#34;)

    ## but now we need to rebuild the surface process information
    self._update_height_for_surface_flows()
    return</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.stream_power_erosion_deposition_rate_local"><code class="name flex">
<span>def <span class="ident">stream_power_erosion_deposition_rate_local</span></span>(<span>self, stream_power, efficiency=0.01, smoothOperator=None, smoothPowerIts=1, smoothDepoIts=1, smoothLowIts=3)</span>
</code></dt>
<dd>
<div class="desc"><p>Function of the SurfaceProcessMesh which computes stream-power erosion and deposition rates
from a given rainfall pattern (self.rainfall_pattern).</p>
<p>In this model we assume a the carrying capacity of the stream is related to the stream power and so is the
erosion rate. The two are related to one another in this particular case by a single contant (everywhere on the mesh)
This does not allow for spatially variable erodability and it does not allow for differences in the dependence
of erosion / deposition on the stream power.</p>
<p>Deposition occurs such that the upstream-integrated eroded sediment does not exceed the carrying capacity at a given
point. To conserve mass, we have to treat internal drainage points carefully and, optionally, smooth the deposition
upstream of the low point. We also have to be careful when stream-power and carrying capacity increase going downstream.
This produces a negative deposition rate when the flow is at capacity. We suppress this behaviour and balance mass across
all other deposition sites but this does mean the capacity is not perfectly satisfied everywhere.</p>
<p>parameters:
efficiency=0.01
: erosion rate for a given stream power compared to carrying capacity
smoothOperator=None
:
smoothPowerIts=1
: Use smoothing function (smoothOperator) n times on stream power
smoothDepoIts=1
: Use smoothing function (smoothOperator) n times on deposition rate
smoothLowIts=1
: Use smoothing function (smoothOperator) n times on low point patches</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stream_power_erosion_deposition_rate_local(self, stream_power,
                                         efficiency=0.01,
                                         smoothOperator=None,
                                         smoothPowerIts=1, smoothDepoIts=1, smoothLowIts=3 ):

    &#34;&#34;&#34;
    Function of the SurfaceProcessMesh which computes stream-power erosion and deposition rates
    from a given rainfall pattern (self.rainfall_pattern).

    In this model we assume a the carrying capacity of the stream is related to the stream power and so is the
    erosion rate. The two are related to one another in this particular case by a single contant (everywhere on the mesh)
    This does not allow for spatially variable erodability and it does not allow for differences in the dependence
    of erosion / deposition on the stream power.

    Deposition occurs such that the upstream-integrated eroded sediment does not exceed the carrying capacity at a given
    point. To conserve mass, we have to treat internal drainage points carefully and, optionally, smooth the deposition
    upstream of the low point. We also have to be careful when stream-power and carrying capacity increase going downstream.
    This produces a negative deposition rate when the flow is at capacity. We suppress this behaviour and balance mass across
    all other deposition sites but this does mean the capacity is not perfectly satisfied everywhere.

    parameters:
     efficiency=0.01          : erosion rate for a given stream power compared to carrying capacity
     smoothOperator=None      :
     smoothPowerIts=1         : Use smoothing function (smoothOperator) n times on stream power
     smoothDepoIts=1          : Use smoothing function (smoothOperator) n times on deposition rate
     smoothLowIts=1           : Use smoothing function (smoothOperator) n times on low point patches
    &#34;&#34;&#34;


    if smooth_operator == None:
        smooth_operator = self.rbf_smoother

    for i in range(0, smoothPowerIts):
        stream_power = smoothOperator(stream_power)

    dhdt_erosion = efficiency*stream_power

    cumulative_eroded_material = self.cumulative_flow(erosion_rate*self.area)
    full_capacity_sediment_load = stream_power   # Constant ?

    # if the sediment load exceeds the capacity, start depositing material
    # use vec.pointwisemin
    transport_limited_eroded_material = np.minimum(cumulative_eroded_material, full_capacity_sediment_load)

    excess = sp.gvec.duplicate()
    excess.setArray(cumulative_eroded_material - transport_limited_eroded_material)

    deposition = excess - self.downhillMat*excess
    depo_sum   = deposition.sum()




    # Now rebalance the fact that we have clipped off the negative deposition which will need
    # to be clawed back downstream (ideally, but for now we can just make a global correction)

    deposition = np.clip(deposition.array, 0.0, 1.0e99)
    deposition *= depo_sum / (depo_sum + 1e-12)


    # The (interior) low points are a bit of a problem - we stomped on the stream power there
    # but this produces a very lumpy deposition at the low point itself and this could (does)
    # make the numerical representation pretty unstable. Instead what we can do is to take that
    # deposition at the low points let it spill into the local area


    ## These will instead be handled by a specific routine &#34;handle_low_points&#34; which is
    ## done once the height has been updated

    if len(self.low_points):
        deposition[self.low_points] = 0.0

    # The flat regions in the domain are also problematic since the deposition there is

    flat_spots = self.identify_flat_spots()

    if len(flat_spots):
        smoothed_deposition = deposition.copy()
        smoothed_deposition[np.invert(flat_spots)] = 0.0
        smoothed_deposition = self.local_area_smoothing(smoothed_deposition, its=2, centre_weight=0.5)
        deposition[flat_spots] = smoothed_deposition[flat_spots]

    deposition_rate = smooth_operator(deposition, smooth_deposition_rate, centre_weight=centre_weight) / self.area

    return erosion_rate, deposition_rate, stream_power</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.stream_power_erosion_deposition_rate_old"><code class="name flex">
<span>def <span class="ident">stream_power_erosion_deposition_rate_old</span></span>(<span>self, efficiency=0.01, smooth_power=3, smooth_low_points=2, smooth_erosion_rate=2, smooth_deposition_rate=2, smooth_operator=None, centre_weight_u=0.5, centre_weight=0.5)</span>
</code></dt>
<dd>
<div class="desc"><p>Function of the SurfaceProcessMesh which computes stream-power erosion and deposition rates
from a given rainfall pattern (self.rainfall_pattern).</p>
<p>In this model we assume a the carrying capacity of the stream is related to the stream power and so is the
erosion rate. The two are related to one another in this particular case by a single contant (everywhere on the mesh)
This does not allow for spatially variable erodability and it does not allow for differences in the dependence
of erosion / deposition on the stream power.</p>
<p>Deposition occurs such that the upstream-integrated eroded sediment does not exceed the carrying capacity at a given
point. To conserve mass, we have to treat internal drainage points carefully and, optionally, smooth the deposition
upstream of the low point. We also have to be careful when stream-power and carrying capacity increase going downstream.
This produces a negative deposition rate when the flow is at capacity. We suppress this behaviour and balance mass across
all other deposition sites but this does mean the capacity is not perfectly satisfied everywhere.</p>
<p>parameters:
efficiency=0.01
: erosion rate for a given stream power compared to carrying capacity
smooth_power=3
: upstream / downstream smoothing of the stream power (number of cycles of smoothing)
smooth_low_points=3
: upstream smoothing of the deposition at low points (number of cycles of smoothing)
smooth_erosion_rate=0
: upstream / downstream smoothing of the computed erosion rate (number of cycles of smoothing)
smooth_deposition_rate=0 : upstream / downstream smoothing of the computed erosion rate (number of cycles of smoothing)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stream_power_erosion_deposition_rate_old(self, efficiency=0.01, smooth_power=3, \
                                         smooth_low_points=2, smooth_erosion_rate=2, \
                                         smooth_deposition_rate=2, smooth_operator=None,
                                         centre_weight_u=0.5, centre_weight=0.5):

    &#34;&#34;&#34;
    Function of the SurfaceProcessMesh which computes stream-power erosion and deposition rates
    from a given rainfall pattern (self.rainfall_pattern).

    In this model we assume a the carrying capacity of the stream is related to the stream power and so is the
    erosion rate. The two are related to one another in this particular case by a single contant (everywhere on the mesh)
    This does not allow for spatially variable erodability and it does not allow for differences in the dependence
    of erosion / deposition on the stream power.

    Deposition occurs such that the upstream-integrated eroded sediment does not exceed the carrying capacity at a given
    point. To conserve mass, we have to treat internal drainage points carefully and, optionally, smooth the deposition
    upstream of the low point. We also have to be careful when stream-power and carrying capacity increase going downstream.
    This produces a negative deposition rate when the flow is at capacity. We suppress this behaviour and balance mass across
    all other deposition sites but this does mean the capacity is not perfectly satisfied everywhere.

    parameters:
     efficiency=0.01          : erosion rate for a given stream power compared to carrying capacity
     smooth_power=3           : upstream / downstream smoothing of the stream power (number of cycles of smoothing)
     smooth_low_points=3      : upstream smoothing of the deposition at low points (number of cycles of smoothing)
     smooth_erosion_rate=0    : upstream / downstream smoothing of the computed erosion rate (number of cycles of smoothing)
     smooth_deposition_rate=0 : upstream / downstream smoothing of the computed erosion rate (number of cycles of smoothing)

    &#34;&#34;&#34;


    if smooth_operator == None:
        smooth_operator = self.streamwise_smoothing

    # Calculate stream power

    ## Model 1 - Local equilibrium

    rainflux = self.rainfall_pattern
    rainfall = self.area * rainflux
    cumulative_rain = self.cumulative_flow(rainfall)

    cumulative_flow_rate = cumulative_rain / self.area

    stream_power = self.uphill_smoothing(cumulative_flow_rate * self.slopeVariable.data, smooth_power, centre_weight=centre_weight_u)

    #  predicted erosion rate from stream power * efficiency
    #  maximum sediment that can be transported is limited by the local carrying capacity (assume also prop to stream power)
    #  whatever cannot be passed on has to be deposited

    erosion_rate = self.streamwise_smoothing(efficiency * stream_power, smooth_erosion_rate, centre_weight=centre_weight)
    full_capacity_sediment_flux = stream_power
    full_capacity_sediment_load = stream_power * self.area
    cumulative_eroded_material = self.cumulative_flow(self.area * erosion_rate)

    # But this can exceed the carrying capacity

    transport_limited_eroded_material = np.minimum(cumulative_eroded_material, full_capacity_sediment_load)
    transport_limited_erosion_rate = transport_limited_eroded_material / self.area

    # And this therefore implies a deposition rate which reduces the total sediment in the system to capacity
    # Calculate this by substracting the deposited amounts from the excess integrated flow. We could then iterate
    # to compute the new erosion rates etc, but here we just spread the sediments around to places where
    # the deposition is positive

    excess = self.gvec.duplicate()
    deposition = self.lvec.duplicate()
    self.lvec.setArray(cumulative_eroded_material - transport_limited_eroded_material)
    self.dm.localToGlobal(self.lvec, excess)
    self.downhillMat.mult(excess, self.gvec)
    self.dm.globalToLocal(excess - self.gvec, deposition)
    depo_sum = deposition.sum()


    # Now rebalance the fact that we have clipped off the negative deposition which will need
    # to be clawed back downstream (ideally, but for now we can just make a global correction)

    deposition = np.clip(deposition.array, 0.0, 1.0e99)
    deposition *= depo_sum / (depo_sum + 1e-12)


    # The (interior) low points are a bit of a problem - we stomped on the stream power there
    # but this produces a very lumpy deposition at the low point itself and this could (does)
    # make the numerical representation pretty unstable. Instead what we can do is to take that
    # deposition at the low points let it spill into the local area


    ## These will instead be handled by a specific routine &#34;handle_low_points&#34; which is
    ## done once the height has been updated

    if len(self.low_points):
        deposition[self.low_points] = 0.0

    # The flat regions in the domain are also problematic since the deposition there is

    flat_spots = self.identify_flat_spots()

    if len(flat_spots):
        smoothed_deposition = deposition.copy()
        smoothed_deposition[np.invert(flat_spots)] = 0.0
        smoothed_deposition = self.local_area_smoothing(smoothed_deposition, its=2, centre_weight=0.5)
        deposition[flat_spots] = smoothed_deposition[flat_spots]

    deposition_rate = smooth_operator(deposition, smooth_deposition_rate, centre_weight=centre_weight) / self.area

    return erosion_rate, deposition_rate, stream_power</code></pre>
</details>
</dd>
<dt id="quagmire.surfmesh.surfmesh.SurfMesh.uphill_propagation"><code class="name flex">
<span>def <span class="ident">uphill_propagation</span></span>(<span>self, points, values, scale=1.0, its=1000, fill=-1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def uphill_propagation(self, points, values, scale=1.0, its=1000, fill=-1):

    t0 = perf_counter()

    local_ID = self.lvec.copy()
    global_ID = self.gvec.copy()

    local_ID.set(fill+1)
    global_ID.set(fill+1)

    identifier = np.empty_like(self.topography.data)
    identifier.fill(fill+1)

    if len(points):
        identifier[points] = values + 1

    local_ID.setArray(identifier)
    self.dm.localToGlobal(local_ID, global_ID)

    delta = global_ID.copy()
    delta.abs()
    rtolerance = delta.max()[1] * 1.0e-10

    for p in range(0, its):

        # self.adjacency[1].multTranspose(global_ID, self.gvec)
        gvec = self.uphill[1] * global_ID
        delta = global_ID - gvec
        delta.abs()
        max_delta = delta.max()[1]

        if max_delta &lt; rtolerance:
            break

        self.gvec.scale(scale)

        if self.dm.comm.Get_size() == 1:
            local_ID.array[:] = gvec.array[:]
        else:
            self.dm.globalToLocal(gvec, local_ID)

        global_ID.array[:] = gvec.array[:]

        identifier = np.maximum(identifier, local_ID.array)
        identifier = self.sync(identifier)

    # Note, the -1 is used to identify out of bounds values

    if self.rank == 0 and self.verbose:
        print(p, &#34; iterations, time = &#34;, perf_counter() - t0)

    return identifier - 1</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="quagmire.topomesh.topomesh.TopoMesh" href="../topomesh/topomesh.html#quagmire.topomesh.topomesh.TopoMesh">TopoMesh</a></b></code>:
<ul class="hlist">
<li><code><a title="quagmire.topomesh.topomesh.TopoMesh.build_cumulative_downhill_matrix" href="../topomesh/topomesh.html#quagmire.topomesh.topomesh.TopoMesh.build_cumulative_downhill_matrix">build_cumulative_downhill_matrix</a></code></li>
<li><code><a title="quagmire.topomesh.topomesh.TopoMesh.build_node_chains" href="../topomesh/topomesh.html#quagmire.topomesh.topomesh.TopoMesh.build_node_chains">build_node_chains</a></code></li>
<li><code><a title="quagmire.topomesh.topomesh.TopoMesh.upstream_integral_fn" href="../topomesh/topomesh.html#quagmire.topomesh.topomesh.TopoMesh.upstream_integral_fn">upstream_integral_fn</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="quagmire.surfmesh" href="index.html">quagmire.surfmesh</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="quagmire.surfmesh.surfmesh.SurfMesh" href="#quagmire.surfmesh.surfmesh.SurfMesh">SurfMesh</a></code></h4>
<ul class="">
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.backfill_points" href="#quagmire.surfmesh.surfmesh.SurfMesh.backfill_points">backfill_points</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.identify_flat_spots" href="#quagmire.surfmesh.surfmesh.SurfMesh.identify_flat_spots">identify_flat_spots</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.identify_global_low_points" href="#quagmire.surfmesh.surfmesh.SurfMesh.identify_global_low_points">identify_global_low_points</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.identify_low_points" href="#quagmire.surfmesh.surfmesh.SurfMesh.identify_low_points">identify_low_points</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.identify_outflow_points" href="#quagmire.surfmesh.surfmesh.SurfMesh.identify_outflow_points">identify_outflow_points</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.landscape_diffusion_critical_slope" href="#quagmire.surfmesh.surfmesh.SurfMesh.landscape_diffusion_critical_slope">landscape_diffusion_critical_slope</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.landscape_evolution_timestep" href="#quagmire.surfmesh.surfmesh.SurfMesh.landscape_evolution_timestep">landscape_evolution_timestep</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.low_points_local_flood_fill" href="#quagmire.surfmesh.surfmesh.SurfMesh.low_points_local_flood_fill">low_points_local_flood_fill</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.low_points_local_patch_fill" href="#quagmire.surfmesh.surfmesh.SurfMesh.low_points_local_patch_fill">low_points_local_patch_fill</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.low_points_swamp_fill" href="#quagmire.surfmesh.surfmesh.SurfMesh.low_points_swamp_fill">low_points_swamp_fill</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.stream_power_erosion_deposition_rate_local" href="#quagmire.surfmesh.surfmesh.SurfMesh.stream_power_erosion_deposition_rate_local">stream_power_erosion_deposition_rate_local</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.stream_power_erosion_deposition_rate_old" href="#quagmire.surfmesh.surfmesh.SurfMesh.stream_power_erosion_deposition_rate_old">stream_power_erosion_deposition_rate_old</a></code></li>
<li><code><a title="quagmire.surfmesh.surfmesh.SurfMesh.uphill_propagation" href="#quagmire.surfmesh.surfmesh.SurfMesh.uphill_propagation">uphill_propagation</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.0</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>